---
title: "AIG: The Dumb Smart Thing That Might Change Everything"
date: 2025-03-15
description: "A look at the fugure of AIG and its widespread impact."
tags: [AI, AIG, UBI, Futurology]
categories: [Technology, AI Trends]
draft: false
---


# **AGI: The Dumb Smart Thing That Might Change Everything**  

Every few months, a new AI breakthrough is hailed as a step toward Artificial General Intelligence (AGI), the fabled "thinking machine" that could match or surpass human intelligence. Lately, I’ve been feeling a mix of excitement and unease about the whole thing. The potential is staggering, but so are the risks. And frankly, right now, AI is still just dumb enough that I’m not scared—yet.  

---

## **Why AGI Feels More Inevitable Than Ever**  

I read a [recent NYT piece](https://www.nytimes.com/2025/03/14/technology/why-im-feeling-the-agi.html) about AGI, and while I didn't find it particularly shocking, it did reinforce something I’ve been thinking a lot about: **AGI isn't a question of if, but when.**  

There are obvious technical hurdles—alignment, reasoning, self-improvement—but there’s also an unstoppable momentum. The smartest minds in the world are chasing it, billions of dollars are being thrown at it, and the breakthroughs are piling up. It’s only a matter of time before we move from "AI that's pretty good at pattern recognition" to "AI that can actually think and plan in a way that feels human."  

That’s where things start to get weird.  

---

## **The Job Apocalypse (But Not Yours… Yet)**  

Most people’s first question about AGI is, “Will it take my job?” The answer is: probably not if you’re doing anything creative or deeply analytical. But if you’re in a **non-creative back-office job—think bookkeeping, low-level legal work, customer support—then yeah, you should be paying attention.**  

The efficiency gains will be too tempting for corporations to ignore. Entire roles will be automated overnight, and that’s when conversations around **Universal Basic Income (UBI)** will go from niche policy debates to mainstream survival strategies.  

UBI was already an interesting concept when automation was picking off warehouse jobs—now imagine what happens when AI starts hollowing out middle-class knowledge work. Governments will have to start thinking about how to redistribute wealth when jobs as we know them start disappearing.  

And it *will* happen.  

---

## **China’s AI Strategy: The Cheat Code No One Talks About**  

One of the biggest factors accelerating AGI isn’t just the rapid improvements in AI models—it’s how **different countries approach AI development.**  

China, for example, has a *huge* advantage over the West. Sam Altman wasn’t wrong when he pointed out that China’s disregard for copyright and intellectual property means they can move much faster. They can scrape and train on everything without worrying about lawsuits, while Western AI companies tiptoe around legal minefields.  

Then there’s the fact that China’s government is **directly bankrolling AI research.** No need to worry about venture capital or short-term profit pressures—just an endless budget to push the technology forward. That’s how you end up with projects like **Manus**, China’s latest AGI-like agent that’s supposedly the closest thing we’ve seen to real AGI.  

If the US and Europe want to stay competitive, they’ll either have to **rethink their AI regulations or accept that China will likely be first to AGI.**  

---

## **Ethical AGI: Do We Even Know What That Means?**  

This is where things get murky. We can all agree that AGI should be developed **ethically**, but what does that even mean?  

- Should it be built to serve humanity or to be an independent entity?  
- Should it have rights if it becomes sentient?  
- Who gets to decide what an AGI is *allowed* to do?  

We already see bias issues with current AI—what happens when those biases get baked into an AGI that makes real decisions? Or worse, what if we create something truly independent and *lose control of it* before we even understand what we've built?  

I don’t know the answers. I don’t think anyone does. But the fact that we’re moving at breakneck speed without clear guidelines is, at best, **reckless**.  

---

## **Final Thoughts: Why I’m Not Freaking Out (Yet)**  

Despite all this, I still *love* AI.  

Right now, it's powerful, useful, and incredibly dumb in just the right ways. It can generate ideas, summarize complex papers, and automate some tedious tasks, but it **doesn’t “think”**—not in a way that threatens human intelligence.  

That’s what keeps me from losing sleep over AGI. Today’s AI is still just a really fancy autocomplete machine. But when that changes—when it stops just predicting the next word and starts *understanding*—that’s when things get truly interesting.  

And that’s when we might not be in control anymore.


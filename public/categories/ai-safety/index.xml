<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI Safety on My Blog</title>
        <link>http://192.168.100.63:1313/categories/ai-safety/</link>
        <description>Recent content in AI Safety on My Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 22 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://192.168.100.63:1313/categories/ai-safety/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Claude 4: The AI That&#39;s So Smart It Scares Its Own Creators</title>
        <link>http://192.168.100.63:1313/musings/claude4/</link>
        <pubDate>Thu, 22 May 2025 00:00:00 +0000</pubDate>
        
        <guid>http://192.168.100.63:1313/musings/claude4/</guid>
        <description>&lt;img src="http://192.168.100.63:1313/img/claude4/header.png" alt="Featured image of post Claude 4: The AI That&#39;s So Smart It Scares Its Own Creators" /&gt;&lt;h1 id=&#34;claude-4-the-ai-thats-so-smart-it-scares-its-own-creators&#34;&gt;&lt;a href=&#34;#claude-4-the-ai-thats-so-smart-it-scares-its-own-creators&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Claude 4: The AI That&amp;rsquo;s So Smart It Scares Its Own Creators
&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Why Anthropic&amp;rsquo;s latest breakthrough comes with some uncomfortable safety warnings&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Anthropic just dropped Claude 4, and the benchmarks are genuinely impressive. But buried in the announcement is something that should make everyone pay attention: this AI is so capable that Anthropic had to activate their highest safety protocols to prevent it from accidentally helping someone build weapons of mass destruction.&lt;/p&gt;
&lt;p&gt;Let me unpack that for you.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-benchmarks-tell-an-impressive-story&#34;&gt;&lt;a href=&#34;#the-benchmarks-tell-an-impressive-story&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Benchmarks Tell an Impressive Story
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://192.168.100.63:1313/img/claude4/swe.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Claude 4 Performance Overview&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;coding-performance-that-actually-matters&#34;&gt;&lt;a href=&#34;#coding-performance-that-actually-matters&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Coding Performance That Actually Matters
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;SWE-Bench Verified scores:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Claude Opus 4: 72.5% (79.4% with parallel test-time compute)&lt;/li&gt;
&lt;li&gt;Anthropic Previous best (Claude Sonnet 3.7): 62.3% (70.3% with parallel test-time compute)&lt;/li&gt;
&lt;li&gt;Industry Next Best OpenAI Codex-1: 72.1%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What this means in practice:&lt;/strong&gt; Claude 4 can solve nearly half of real-world software engineering problems from GitHub issues. That&amp;rsquo;s not just impressive - it&amp;rsquo;s getting into territory where AI could handle significant portions of actual development work.&lt;/p&gt;
&lt;h3 id=&#34;the-agentic-capabilities-jump&#34;&gt;&lt;a href=&#34;#the-agentic-capabilities-jump&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Agentic Capabilities Jump
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Claude 4 can now:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Handle complex, multi-step tasks that take hours to complete&lt;/li&gt;
&lt;li&gt;Use computers like humans do (clicking, typing, navigating interfaces)&lt;/li&gt;
&lt;li&gt;Write and debug code across entire projects, not just individual functions&lt;/li&gt;
&lt;li&gt;Understand and follow nuanced instructions across long conversations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Personal take:&lt;/strong&gt; This feels like the first AI that could actually replace junior developers on routine tasks, not just assist them.&lt;/p&gt;
&lt;h3 id=&#34;technical-specifications-and-pricing&#34;&gt;&lt;a href=&#34;#technical-specifications-and-pricing&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Technical Specifications and Pricing
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;http://192.168.100.63:1313/img/claude4/price.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Claude 4 Pricing Structure&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Claude Opus 4:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most intelligent model for complex tasks&lt;/li&gt;
&lt;li&gt;200K context window&lt;/li&gt;
&lt;li&gt;Input: $15 / MTok&lt;/li&gt;
&lt;li&gt;Output: $75 / MTok&lt;/li&gt;
&lt;li&gt;50% discount with batch processing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Claude Sonnet 4:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimal balance of intelligence, cost, and speed&lt;/li&gt;
&lt;li&gt;200K context window&lt;/li&gt;
&lt;li&gt;Input: $3 / MTok&lt;/li&gt;
&lt;li&gt;Output: $15 / MTok&lt;/li&gt;
&lt;li&gt;50% discount with batch processing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Both models include prompt caching capabilities for improved efficiency&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;mathematical-and-scientific-reasoning&#34;&gt;&lt;a href=&#34;#mathematical-and-scientific-reasoning&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Mathematical and Scientific Reasoning
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;GPQA Diamond (graduate-level science questions):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Claude Opus 4: 83.3%&lt;/li&gt;
&lt;li&gt;Claude Sonnet 3.7: 78.2 %&lt;/li&gt;
&lt;li&gt;Human PhD experts: ~69%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://192.168.100.63:1313/img/claude4/performance.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Claude 4 GPQA Performance&#34;
	
	
&gt;
&lt;em&gt;Claude 4 now outperforms most PhD experts on graduate-level science questions&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Translation:&lt;/strong&gt; Claude 4 is now better than most PhD scientists at answering graduate-level questions in their own fields. That&amp;rsquo;s&amp;hellip; concerning in ways I&amp;rsquo;ll get to.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-safety-red-flag-everyones-ignoring&#34;&gt;&lt;a href=&#34;#the-safety-red-flag-everyones-ignoring&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Safety Red Flag Everyone&amp;rsquo;s Ignoring
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://192.168.100.63:1313/img/claude4/asl.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ASL-3 Safety Framework&#34;
	
	
&gt;
&lt;em&gt;Anthropic&amp;rsquo;s AI Safety Level framework - Claude Opus 4 triggered ASL-3 protocols&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;asl-3-when-your-ai-gets-too-smart-for-comfort&#34;&gt;&lt;a href=&#34;#asl-3-when-your-ai-gets-too-smart-for-comfort&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;ASL-3: When Your AI Gets Too Smart for Comfort
&lt;/h3&gt;&lt;p&gt;Here&amp;rsquo;s the part that should make everyone nervous: &lt;strong&gt;Anthropic activated their AI Safety Level 3 protocols specifically because Claude Opus 4 could potentially help people create chemical, biological, radiological, and nuclear weapons.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Let me be clear about what this means:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This isn&amp;rsquo;t theoretical - they tested it&lt;/li&gt;
&lt;li&gt;The AI demonstrated &amp;ldquo;meaningful assistance&amp;rdquo; to people with basic technical knowledge&lt;/li&gt;
&lt;li&gt;Anthropic&amp;rsquo;s own safety team decided this crossed a line that required maximum precautions&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www-cdn.anthropic.com/807c59454757214bfd37592d6e048079cd7a7728.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Full technical details available in Anthropic&amp;rsquo;s safety evaluation report&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-asl-3-actually-involves&#34;&gt;&lt;a href=&#34;#what-asl-3-actually-involves&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;What ASL-3 Actually Involves
&lt;/h3&gt;&lt;figure&gt;&lt;img src=&#34;http://192.168.100.63:1313/images/claude4/asl3-security-measures.png&#34;
    alt=&#34;Diagram showing enhanced security measures for ASL-3 AI systems&#34;&gt;&lt;figcaption&gt;
      &lt;h4&gt;ASL-3 Security Protocols&lt;/h4&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;Enhanced security measures:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stronger cybersecurity around model deployment&lt;/li&gt;
&lt;li&gt;More aggressive content filtering&lt;/li&gt;
&lt;li&gt;Additional monitoring and logging&lt;/li&gt;
&lt;li&gt;Restricted access protocols&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The uncomfortable reality:&lt;/strong&gt; We now have an AI so intelligent that its creators are worried about it being weaponized, even accidentally.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;my-take-were-moving-faster-than-we-should&#34;&gt;&lt;a href=&#34;#my-take-were-moving-faster-than-we-should&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;My Take: We&amp;rsquo;re Moving Faster Than We Should
&lt;/h2&gt;&lt;h3 id=&#34;the-capabilities-are-real-and-impressive&#34;&gt;&lt;a href=&#34;#the-capabilities-are-real-and-impressive&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Capabilities Are Real (And Impressive)
&lt;/h3&gt;&lt;p&gt;I&amp;rsquo;ve been testing Claude 4 for coding tasks, and the improvement over previous versions is substantial. It can:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Handle entire project architectures&lt;/strong&gt; instead of just individual functions
&lt;strong&gt;Debug complex multi-file codebases&lt;/strong&gt; with genuine understanding of dependencies
&lt;strong&gt;Write production-ready code&lt;/strong&gt; that often needs minimal human review
&lt;strong&gt;Explain its reasoning&lt;/strong&gt; in ways that actually help you understand the solution&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bottom line:&lt;/strong&gt; This is the first AI that feels like it could genuinely replace significant portions of knowledge work, not just augment it.&lt;/p&gt;
&lt;h3 id=&#34;but-the-safety-implications-are-terrifying&#34;&gt;&lt;a href=&#34;#but-the-safety-implications-are-terrifying&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;But the Safety Implications Are Terrifying
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Here&amp;rsquo;s what keeps me up at night:&lt;/strong&gt; If Claude Opus 4 can provide &amp;ldquo;meaningful assistance&amp;rdquo; in creating weapons of mass destruction, what else can it help with that we haven&amp;rsquo;t tested for?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consider the implications:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sophisticated cyber attacks&lt;/li&gt;
&lt;li&gt;Advanced fraud schemes&lt;/li&gt;
&lt;li&gt;Social engineering at scale&lt;/li&gt;
&lt;li&gt;Misinformation campaigns with technical depth&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt; We&amp;rsquo;re releasing these capabilities to the public while still figuring out the safety implications.&lt;/p&gt;
&lt;h3 id=&#34;the-timing-feels-wrong&#34;&gt;&lt;a href=&#34;#the-timing-feels-wrong&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Timing Feels Wrong
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What we have:&lt;/strong&gt; An AI that&amp;rsquo;s smart enough to potentially help with WMD development
&lt;strong&gt;What we don&amp;rsquo;t have:&lt;/strong&gt; Robust frameworks for preventing misuse at scale&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The math is simple:&lt;/strong&gt; The capabilities are advancing faster than our ability to safely deploy them.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-real-world-impact&#34;&gt;&lt;a href=&#34;#the-real-world-impact&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Real-World Impact
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://192.168.100.63:1313/img/claude4/agent.gif&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Claude 4 Capabilities Overview&#34;
	
	
&gt;
&lt;em&gt;Claude 4&amp;rsquo;s expanded agentic capabilities for complex, multi-step tasks&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;for-developers-and-businesses&#34;&gt;&lt;a href=&#34;#for-developers-and-businesses&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;For Developers and Businesses
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;The opportunities are massive:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dramatically faster software development cycles&lt;/li&gt;
&lt;li&gt;AI that can handle complex, multi-step business processes&lt;/li&gt;
&lt;li&gt;Genuine automation of knowledge work that previously required human intelligence&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;But the risks are real too:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dependence on systems we don&amp;rsquo;t fully understand or control&lt;/li&gt;
&lt;li&gt;Potential for AI to make mistakes in high-stakes situations&lt;/li&gt;
&lt;li&gt;Economic disruption as AI capabilities expand rapidly&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;for-society&#34;&gt;&lt;a href=&#34;#for-society&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;For Society
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;The positive scenario:&lt;/strong&gt; AI accelerates solutions to major problems - climate change, medical research, educational accessibility.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The concerning scenario:&lt;/strong&gt; AI capabilities outpace our ability to govern them responsibly, leading to misuse by bad actors or unintended consequences at scale.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My assessment:&lt;/strong&gt; We&amp;rsquo;re probably getting both simultaneously.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-this-means-going-forward&#34;&gt;&lt;a href=&#34;#what-this-means-going-forward&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;What This Means Going Forward
&lt;/h2&gt;&lt;h3 id=&#34;the-genie-is-out-of-the-bottle&#34;&gt;&lt;a href=&#34;#the-genie-is-out-of-the-bottle&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Genie is Out of the Bottle
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Anthropic can implement ASL-3 protocols, but:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Other companies may not have equivalent safety standards&lt;/li&gt;
&lt;li&gt;Open-source alternatives will eventually match these capabilities&lt;/li&gt;
&lt;li&gt;The knowledge of how to build such systems is spreading rapidly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Translation:&lt;/strong&gt; The safety measures are important but probably temporary. The real question is how we adapt society to AI this capable.&lt;/p&gt;
&lt;h3 id=&#34;we-need-better-governance-fast&#34;&gt;&lt;a href=&#34;#we-need-better-governance-fast&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;We Need Better Governance (Fast)
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Current approach:&lt;/strong&gt; Build first, figure out safety later
&lt;strong&gt;What we need:&lt;/strong&gt; Proactive frameworks for managing AI capabilities before they&amp;rsquo;re deployed&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The challenge:&lt;/strong&gt; Innovation is moving faster than regulation, and the stakes are getting higher.&lt;/p&gt;
&lt;h3 id=&#34;the-business-reality&#34;&gt;&lt;a href=&#34;#the-business-reality&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Business Reality
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Companies will use Claude 4&lt;/strong&gt; because the competitive advantages are too significant to ignore.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This creates pressure&lt;/strong&gt; for even more capable AI systems, regardless of safety concerns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The result:&lt;/strong&gt; An arms race where capability development outpaces safety development.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;my-honest-assessment&#34;&gt;&lt;a href=&#34;#my-honest-assessment&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;My Honest Assessment
&lt;/h2&gt;&lt;h3 id=&#34;claude-4-is-genuinely-impressive&#34;&gt;&lt;a href=&#34;#claude-4-is-genuinely-impressive&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Claude 4 is Genuinely Impressive
&lt;/h3&gt;&lt;p&gt;The benchmarks don&amp;rsquo;t lie - this is a significant leap in AI capabilities. For coding, reasoning, and complex task execution, it&amp;rsquo;s genuinely better than most humans at many tasks.&lt;/p&gt;
&lt;h3 id=&#34;but-the-safety-timing-is-concerning&#34;&gt;&lt;a href=&#34;#but-the-safety-timing-is-concerning&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;But the Safety Timing is Concerning
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;The fact that Anthropic had to activate ASL-3 protocols suggests we&amp;rsquo;re entering territory where AI capabilities could genuinely threaten public safety.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The bigger concern:&lt;/strong&gt; If the &amp;ldquo;responsible&amp;rdquo; AI company is worried about their own creation, what about less cautious actors?&lt;/p&gt;
&lt;h3 id=&#34;were-in-uncharted-territory&#34;&gt;&lt;a href=&#34;#were-in-uncharted-territory&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;We&amp;rsquo;re in Uncharted Territory
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Previous AI releases felt like powerful tools.&lt;/strong&gt; Claude 4 feels like something different - an artificial intelligence that&amp;rsquo;s approaching human-level reasoning in many domains.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;That&amp;rsquo;s exciting and terrifying in equal measure.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;the-bottom-line&#34;&gt;&lt;a href=&#34;#the-bottom-line&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;The Bottom Line
&lt;/h2&gt;&lt;p&gt;Claude 4 represents a genuine breakthrough in AI capabilities. The benchmarks are impressive, the applications are transformative, and the business implications are massive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But it also represents a new category of AI risk&lt;/strong&gt; - systems so capable that even their creators are concerned about potential misuse.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My take:&lt;/strong&gt; We should be excited about the possibilities while being much more concerned about the risks than most people currently are.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The question isn&amp;rsquo;t whether AI this capable will change the world&lt;/strong&gt; - it definitely will.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The question is whether we can manage that change responsibly&lt;/strong&gt; while it&amp;rsquo;s happening at unprecedented speed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Right now, I&amp;rsquo;m not confident we can.&lt;/strong&gt; But Claude 4 is here regardless, and we&amp;rsquo;re all about to find out what happens when AI gets this smart.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;The most significant technological breakthroughs often come with the most significant risks. Claude 4 might be both the most impressive and most concerning AI release yet.&lt;/em&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
